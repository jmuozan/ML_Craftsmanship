{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.13-cp311-cp311-macosx_11_0_universal2.whl (50.1 MB)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.9.0.80-cp37-abi3-macosx_11_0_arm64.whl (35.4 MB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.2-cp311-cp311-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.4.2-cp311-cp311-macosx_12_0_arm64.whl (10.5 MB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.8.4-cp311-cp311-macosx_11_0_arm64.whl (7.5 MB)\n",
      "Collecting absl-py\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Collecting attrs>=19.1.0\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Collecting jax\n",
      "  Downloading jax-0.4.27-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m929.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jaxlib\n",
      "  Downloading jaxlib-0.4.27-cp311-cp311-macosx_11_0_arm64.whl (63.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting opencv-contrib-python\n",
      "  Using cached opencv_contrib_python-4.9.0.80-cp37-abi3-macosx_11_0_arm64.whl (44.2 MB)\n",
      "Collecting protobuf<5,>=4.25.3\n",
      "  Using cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Collecting sounddevice>=0.4.4\n",
      "  Using cached sounddevice-0.4.6-py3-none-macosx_10_6_x86_64.macosx_10_6_universal2.whl (107 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Collecting scipy>=1.6.0\n",
      "  Using cached scipy-1.13.0-cp311-cp311-macosx_12_0_arm64.whl (30.3 MB)\n",
      "Collecting joblib>=1.2.0\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.2.1-cp311-cp311-macosx_11_0_arm64.whl (245 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.51.0-cp311-cp311-macosx_10_9_universal2.whl (2.8 MB)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Using cached kiwisolver-1.4.5-cp311-cp311-macosx_11_0_arm64.whl (66 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from matplotlib) (24.0)\n",
      "Collecting pillow>=8\n",
      "  Using cached pillow-10.3.0-cp311-cp311-macosx_11_0_arm64.whl (3.4 MB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting CFFI>=1.0\n",
      "  Using cached cffi-1.16.0-cp311-cp311-macosx_11_0_arm64.whl (176 kB)\n",
      "Collecting ml-dtypes>=0.2.0\n",
      "  Using cached ml_dtypes-0.4.0-cp311-cp311-macosx_10_9_universal2.whl (390 kB)\n",
      "Collecting opt-einsum\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting pycparser\n",
      "  Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: pytz, flatbuffers, tzdata, threadpoolctl, pyparsing, pycparser, protobuf, pillow, numpy, kiwisolver, joblib, fonttools, cycler, attrs, absl-py, scipy, pandas, opt-einsum, opencv-python, opencv-contrib-python, ml-dtypes, contourpy, CFFI, sounddevice, scikit-learn, matplotlib, jaxlib, jax, mediapipe\n",
      "Successfully installed CFFI-1.16.0 absl-py-2.1.0 attrs-23.2.0 contourpy-1.2.1 cycler-0.12.1 flatbuffers-24.3.25 fonttools-4.51.0 jax-0.4.27 jaxlib-0.4.27 joblib-1.4.2 kiwisolver-1.4.5 matplotlib-3.8.4 mediapipe-0.10.13 ml-dtypes-0.4.0 numpy-1.26.4 opencv-contrib-python-4.9.0.80 opencv-python-4.9.0.80 opt-einsum-3.3.0 pandas-2.2.2 pillow-10.3.0 protobuf-4.25.3 pycparser-2.22 pyparsing-3.1.2 pytz-2024.1 scikit-learn-1.4.2 scipy-1.13.0 sounddevice-0.4.6 threadpoolctl-3.5.0 tzdata-2024.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Install libraries\n",
    "!pip install mediapipe opencv-python pandas scikit-learn numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Libraries\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 11:10:41.133 python[5123:138801] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1715159442.393856  138801 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2 Pro\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "I0000 00:00:1715159442.399487  138801 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2 Pro\n",
      "/Users/jorgemuyo/Desktop/ML_Craftsmanship/.venv/lib/python3.11/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Check that the camera and mediapipe are working\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video capture\")\n",
    "else:\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose, \\\n",
    "        mp.solutions.hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "        while cap.isOpened():\n",
    "            ret, image = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Error: Unable to read frame from video capture\")\n",
    "                break\n",
    "\n",
    "            # Flip image to simulate mirror view\n",
    "            image = cv2.flip(image, 1)\n",
    "\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            # Make detections\n",
    "            pose_results = pose.process(image)\n",
    "            hand_results = hands.process(image)\n",
    "\n",
    "            # RGB 2 BGR\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Draw points\n",
    "            if pose_results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image,\n",
    "                    pose_results.pose_landmarks,\n",
    "                    mp_pose.POSE_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                    mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2),\n",
    "                )\n",
    "\n",
    "            if hand_results.multi_hand_landmarks:\n",
    "                for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image,\n",
    "                        hand_landmarks,\n",
    "                        mp.solutions.hands.HAND_CONNECTIONS,\n",
    "                        mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),\n",
    "                        mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=2),\n",
    "                    )\n",
    "\n",
    "            cv2.imshow(\"Raw Webcam Feed\", image)\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Record video for data capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video capture\")\n",
    "else:\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30 \n",
    "    print(f\"Video Resolution: {width}x{height} at {fps} FPS\")\n",
    "\n",
    "    # Define the codec\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID') \n",
    "    out = cv2.VideoWriter('output.avi', fourcc, fps, (width, height))\n",
    "\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            print(\"Error: Unable to read frame from video capture\")\n",
    "            break\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_rgb.flags.writeable = False\n",
    "        results = hands.process(frame_rgb)  \n",
    "        frame_rgb.flags.writeable = True\n",
    "        frame = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Write every frame\n",
    "        out.write(frame)\n",
    "\n",
    "        cv2.imshow('MediaPipe Hands', frame)  \n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'): # 'q' to quit\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Create CSV to store data\n",
    "headers = ['class', 'accuracy', 'sequence'] \n",
    "headers.extend([f'pose_{coord}{i}' for i in range(33) for coord in ('x', 'y', 'z', 'v')])\n",
    "headers.extend([f'{hand}_{coord}{i}' for hand in ('right_hand', 'left_hand') for i in range(21) for coord in ('x', 'y', 'z', 'v')])\n",
    "\n",
    "with open('coordinates_1.csv', mode='w', newline='') as file:\n",
    "    csv_writer = csv.writer(file)\n",
    "    csv_writer.writerow(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1715159732.279918  138801 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2 Pro\n",
      "I0000 00:00:1715159732.284361  138801 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2 Pro\n",
      "/Users/jorgemuyo/Desktop/ML_Craftsmanship/.venv/lib/python3.11/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "/var/folders/wv/_x9hjmys03x5gnbfl70ry2sr0000gn/T/ipykernel_5123/1173199726.py:113: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'movement_1' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df['accuracy'].notna(), 'class'] = 'movement_1'  # Only fill 'class' where there's recorded data\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Capture data for first 'movement'\n",
    "cap = cv2.VideoCapture('_.mp4')\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video capture\")\n",
    "else:\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter('processed_output.avi', fourcc, fps, (width, height))\n",
    "\n",
    "    # MediaPipe initialization\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    pose_drawing_spec = mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4)\n",
    "    hand_drawing_spec = mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2)\n",
    "\n",
    "    record = False\n",
    "    accuracy = None\n",
    "    sequence = -1  \n",
    "    recording_state = None  \n",
    "\n",
    "    with open('coordinates_1.csv', mode='a', newline='') as file:\n",
    "        csv_writer = csv.writer(file)\n",
    "\n",
    "        while cap.isOpened():\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                print(\"Error: Unable to read frame from video capture\")\n",
    "                break\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_rgb.flags.writeable = False\n",
    "            pose_results = pose.process(frame_rgb)\n",
    "            hand_results = hands.process(frame_rgb)\n",
    "            frame_rgb.flags.writeable = True\n",
    "            frame = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Drawing the landmarks\n",
    "            if pose_results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame,\n",
    "                    pose_results.pose_landmarks,\n",
    "                    mp_pose.POSE_CONNECTIONS,\n",
    "                    landmark_drawing_spec=pose_drawing_spec,\n",
    "                    connection_drawing_spec=pose_drawing_spec)\n",
    "\n",
    "            if hand_results.multi_hand_landmarks:\n",
    "                for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        frame,\n",
    "                        hand_landmarks,\n",
    "                        mp_hands.HAND_CONNECTIONS,\n",
    "                        landmark_drawing_spec=hand_drawing_spec,\n",
    "                        connection_drawing_spec=hand_drawing_spec)\n",
    "\n",
    "            row = ['', accuracy, sequence if record else -1]\n",
    "\n",
    "            if pose_results.pose_landmarks:\n",
    "                for lm in pose_results.pose_landmarks.landmark:\n",
    "                    visibility_binary = 1 if lm.visibility > 0.3 else 0\n",
    "                    row.extend([lm.x, lm.y, lm.z, visibility_binary])\n",
    "            else:\n",
    "                row.extend([0] * 33 * 4)\n",
    "\n",
    "            for hand in ('right_hand', 'left_hand'):\n",
    "                found = False\n",
    "                if hand_results.multi_hand_landmarks:\n",
    "                    for hand_landmarks, handedness in zip(hand_results.multi_hand_landmarks, hand_results.multi_handedness):\n",
    "                        if handedness.classification[0].label == ('Right' if hand == 'right_hand' else 'Left'):\n",
    "                            for lm in hand_landmarks.landmark:\n",
    "                                visibility_binary = 1 if lm.visibility > 0.2 else 0\n",
    "                                row.extend([lm.x, lm.y, lm.z, visibility_binary])\n",
    "                            found = True\n",
    "                            break\n",
    "                if not found:\n",
    "                    row.extend([0] * 21 * 4)\n",
    "\n",
    "            if record:\n",
    "                csv_writer.writerow(row)\n",
    "\n",
    "            out.write(frame)\n",
    "            cv2.imshow('MediaPipe Pose', frame)\n",
    "            key = cv2.waitKey(5) & 0xFF\n",
    "            if key == ord('r') or key == ord('w'):\n",
    "                new_state = chr(key)\n",
    "                if new_state != recording_state:\n",
    "                    sequence += 1  # Increment sequence only when state changes\n",
    "                    recording_state = new_state\n",
    "                record = True\n",
    "                accuracy = 1 if key == ord('r') else 0\n",
    "            elif key == ord('s'):\n",
    "                record = False\n",
    "                recording_state = None  # Reset recording state\n",
    "            elif key == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# After Video capture data write 'class' for first movement\n",
    "df = pd.read_csv('coordinates_1.csv')\n",
    "df.loc[df['accuracy'].notna(), 'class'] = 'movement_1'  # Only fill 'class' where there's recorded data\n",
    "df.to_csv('coordinates_1.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Capture data for the second 'class' in another CSV\n",
    "cap = cv2.VideoCapture('output.avi')\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video capture\")\n",
    "else:\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter('processed_output.avi', fourcc, fps, (width, height))\n",
    "\n",
    "    # MediaPipe\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    drawing_spec = mp_drawing.DrawingSpec(thickness=2, circle_radius=2)\n",
    "\n",
    "    record = False\n",
    "    accuracy = None \n",
    "    with open('coordinates_2.csv', mode='a', newline='') as file:\n",
    "        csv_writer = csv.writer(file)\n",
    "\n",
    "        while cap.isOpened():\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                print(\"Error: Unable to read frame from video capture\")\n",
    "                break\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_rgb.flags.writeable = False\n",
    "            pose_results = pose.process(frame_rgb)\n",
    "            hand_results = hands.process(frame_rgb)\n",
    "            frame_rgb.flags.writeable = True\n",
    "            frame = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            row = ['', accuracy] if record else ['', '']\n",
    "\n",
    "            if pose_results.pose_landmarks:\n",
    "                for lm in pose_results.pose_landmarks.landmark:\n",
    "                    visibility_binary = 1 if lm.visibility > 0.3 else 0\n",
    "                    row.extend([lm.x, lm.y, lm.z, visibility_binary])\n",
    "\n",
    "            if not pose_results.pose_landmarks:\n",
    "                row.extend([0] * 33 * 4)\n",
    "\n",
    "            for hand in ('right_hand', 'left_hand'):\n",
    "                found = False\n",
    "                if hand_results.multi_hand_landmarks:\n",
    "                    for hand_landmarks, handedness in zip(hand_results.multi_hand_landmarks, hand_results.multi_handedness):\n",
    "                        if handedness.classification[0].label == ('Right' if hand == 'right_hand' else 'Left'):\n",
    "                            for lm in hand_landmarks.landmark:\n",
    "                                visibility_binary = 1 if lm.visibility > 0.3 else 0\n",
    "                                row.extend([lm.x, lm.y, lm.z, visibility_binary])\n",
    "                            found = True\n",
    "                            break\n",
    "                if not found:\n",
    "                    row.extend([0] * 21 * 4)\n",
    "\n",
    "            if record:\n",
    "                csv_writer.writerow(row)\n",
    "\n",
    "            out.write(frame)\n",
    "            cv2.imshow('MediaPipe Pose', frame)\n",
    "            key = cv2.waitKey(5) & 0xFF\n",
    "            if key == ord('r'):\n",
    "                record = True\n",
    "                accuracy = 1\n",
    "            elif key == ord('w'):\n",
    "                record = True\n",
    "                accuracy = 0\n",
    "            elif key == ord('s'):\n",
    "                record = False\n",
    "            elif key == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Write in new CSV without headers, later we will join\n",
    "df = pd.read_csv('coordinates_2.csv', header=None)\n",
    "df.loc[df[1].notna(), 0] = 'movement_2'\n",
    "df.to_csv('coordinates_2.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Join all the CSVs of the different movements\n",
    "df1 = pd.read_csv('coordinates_1.csv', header=None)\n",
    "df2 = pd.read_csv('coordinates_2.csv', header=None)\n",
    "\n",
    "# Concatenate along rows\n",
    "combined_df = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "\n",
    "# Save combined DataFrame to a new CSV\n",
    "combined_path = 'combined_coordinates.csv'\n",
    "combined_df.to_csv(combined_path, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Delete not important data\n",
    "data = pd.read_csv('combined_coordinates.csv')\n",
    "\n",
    "# Display column names to understand what columns are actually in the dataset\n",
    "print(data.columns.tolist())\n",
    "\n",
    "# Define columns to remove by ensuring they exist in the DataFrame's columns\n",
    "columns_to_remove_1 = [f\"pose_{c}{i}\" for c in ['x', 'y', 'z', 'v'] for i in range(0, 11)]\n",
    "columns_to_remove_2 = [f\"pose_{c}{i}\" for c in ['x', 'y', 'z', 'v'] for i in range(23, 33)]\n",
    "columns_to_remove = [col for col in (columns_to_remove_1 + columns_to_remove_2) if col in data.columns]\n",
    "\n",
    "# Drop these columns from the DataFrame\n",
    "data_filtered = data.drop(columns=columns_to_remove)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "data_filtered.to_csv('filtered_coordinates.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Reduce decimal points\n",
    "data = pd.read_csv('filtered_coordinates.csv')\n",
    "data = data.round(3)\n",
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mynewv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
