{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.13-cp311-cp311-macosx_11_0_universal2.whl (50.1 MB)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.9.0.80-cp37-abi3-macosx_11_0_arm64.whl (35.4 MB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.2-cp311-cp311-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.4.2-cp311-cp311-macosx_12_0_arm64.whl (10.5 MB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.8.4-cp311-cp311-macosx_11_0_arm64.whl (7.5 MB)\n",
      "Collecting absl-py\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Collecting attrs>=19.1.0\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Collecting jax\n",
      "  Downloading jax-0.4.27-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m929.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jaxlib\n",
      "  Downloading jaxlib-0.4.27-cp311-cp311-macosx_11_0_arm64.whl (63.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting opencv-contrib-python\n",
      "  Using cached opencv_contrib_python-4.9.0.80-cp37-abi3-macosx_11_0_arm64.whl (44.2 MB)\n",
      "Collecting protobuf<5,>=4.25.3\n",
      "  Using cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Collecting sounddevice>=0.4.4\n",
      "  Using cached sounddevice-0.4.6-py3-none-macosx_10_6_x86_64.macosx_10_6_universal2.whl (107 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Collecting scipy>=1.6.0\n",
      "  Using cached scipy-1.13.0-cp311-cp311-macosx_12_0_arm64.whl (30.3 MB)\n",
      "Collecting joblib>=1.2.0\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.2.1-cp311-cp311-macosx_11_0_arm64.whl (245 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.51.0-cp311-cp311-macosx_10_9_universal2.whl (2.8 MB)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Using cached kiwisolver-1.4.5-cp311-cp311-macosx_11_0_arm64.whl (66 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from matplotlib) (24.0)\n",
      "Collecting pillow>=8\n",
      "  Using cached pillow-10.3.0-cp311-cp311-macosx_11_0_arm64.whl (3.4 MB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting CFFI>=1.0\n",
      "  Using cached cffi-1.16.0-cp311-cp311-macosx_11_0_arm64.whl (176 kB)\n",
      "Collecting ml-dtypes>=0.2.0\n",
      "  Using cached ml_dtypes-0.4.0-cp311-cp311-macosx_10_9_universal2.whl (390 kB)\n",
      "Collecting opt-einsum\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting pycparser\n",
      "  Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: pytz, flatbuffers, tzdata, threadpoolctl, pyparsing, pycparser, protobuf, pillow, numpy, kiwisolver, joblib, fonttools, cycler, attrs, absl-py, scipy, pandas, opt-einsum, opencv-python, opencv-contrib-python, ml-dtypes, contourpy, CFFI, sounddevice, scikit-learn, matplotlib, jaxlib, jax, mediapipe\n",
      "Successfully installed CFFI-1.16.0 absl-py-2.1.0 attrs-23.2.0 contourpy-1.2.1 cycler-0.12.1 flatbuffers-24.3.25 fonttools-4.51.0 jax-0.4.27 jaxlib-0.4.27 joblib-1.4.2 kiwisolver-1.4.5 matplotlib-3.8.4 mediapipe-0.10.13 ml-dtypes-0.4.0 numpy-1.26.4 opencv-contrib-python-4.9.0.80 opencv-python-4.9.0.80 opt-einsum-3.3.0 pandas-2.2.2 pillow-10.3.0 protobuf-4.25.3 pycparser-2.22 pyparsing-3.1.2 pytz-2024.1 scikit-learn-1.4.2 scipy-1.13.0 sounddevice-0.4.6 threadpoolctl-3.5.0 tzdata-2024.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Install libraries\n",
    "!pip install mediapipe opencv-python pandas scikit-learn numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Libraries\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 11:10:41.133 python[5123:138801] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1715159442.393856  138801 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2 Pro\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "I0000 00:00:1715159442.399487  138801 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2 Pro\n",
      "/Users/jorgemuyo/Desktop/ML_Craftsmanship/.venv/lib/python3.11/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Check that the camera and mediapipe are working\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video capture\")\n",
    "else:\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose, \\\n",
    "        mp.solutions.hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "        while cap.isOpened():\n",
    "            ret, image = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Error: Unable to read frame from video capture\")\n",
    "                break\n",
    "\n",
    "            # Flip image to simulate mirror view\n",
    "            image = cv2.flip(image, 1)\n",
    "\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            # Make detections\n",
    "            pose_results = pose.process(image)\n",
    "            hand_results = hands.process(image)\n",
    "\n",
    "            # RGB 2 BGR\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Draw points\n",
    "            if pose_results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image,\n",
    "                    pose_results.pose_landmarks,\n",
    "                    mp_pose.POSE_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                    mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2),\n",
    "                )\n",
    "\n",
    "            if hand_results.multi_hand_landmarks:\n",
    "                for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image,\n",
    "                        hand_landmarks,\n",
    "                        mp.solutions.hands.HAND_CONNECTIONS,\n",
    "                        mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),\n",
    "                        mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=2),\n",
    "                    )\n",
    "\n",
    "            cv2.imshow(\"Raw Webcam Feed\", image)\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Record video for data capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video capture\")\n",
    "else:\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30 \n",
    "    print(f\"Video Resolution: {width}x{height} at {fps} FPS\")\n",
    "\n",
    "    # Define the codec\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID') \n",
    "    out = cv2.VideoWriter('output.avi', fourcc, fps, (width, height))\n",
    "\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            print(\"Error: Unable to read frame from video capture\")\n",
    "            break\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_rgb.flags.writeable = False\n",
    "        results = hands.process(frame_rgb)  \n",
    "        frame_rgb.flags.writeable = True\n",
    "        frame = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Write every frame\n",
    "        out.write(frame)\n",
    "\n",
    "        cv2.imshow('MediaPipe Hands', frame)  \n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'): # 'q' to quit\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Create CSV to store data\n",
    "headers = ['class', 'accuracy', 'sequence'] \n",
    "headers.extend([f'pose_{coord}{i}' for i in range(33) for coord in ('x', 'y', 'z', 'v')])\n",
    "headers.extend([f'{hand}_{coord}{i}' for hand in ('right_hand', 'left_hand') for i in range(21) for coord in ('x', 'y', 'z', 'v')])\n",
    "\n",
    "with open('coordinates_1.csv', mode='w', newline='') as file:\n",
    "    csv_writer = csv.writer(file)\n",
    "    csv_writer.writerow(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1715159732.279918  138801 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2 Pro\n",
      "I0000 00:00:1715159732.284361  138801 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2 Pro\n",
      "/Users/jorgemuyo/Desktop/ML_Craftsmanship/.venv/lib/python3.11/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "/var/folders/wv/_x9hjmys03x5gnbfl70ry2sr0000gn/T/ipykernel_5123/1173199726.py:113: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'movement_1' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df['accuracy'].notna(), 'class'] = 'movement_1'  # Only fill 'class' where there's recorded data\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Capture data for first 'movement'\n",
    "cap = cv2.VideoCapture('_.mp4')\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video capture\")\n",
    "else:\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter('processed_output.avi', fourcc, fps, (width, height))\n",
    "\n",
    "    # MediaPipe initialization\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    pose_drawing_spec = mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4)\n",
    "    hand_drawing_spec = mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2)\n",
    "\n",
    "    record = False\n",
    "    accuracy = None\n",
    "    sequence = -1  \n",
    "    recording_state = None  \n",
    "\n",
    "    with open('coordinates_1.csv', mode='a', newline='') as file:\n",
    "        csv_writer = csv.writer(file)\n",
    "\n",
    "        while cap.isOpened():\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                print(\"Error: Unable to read frame from video capture\")\n",
    "                break\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_rgb.flags.writeable = False\n",
    "            pose_results = pose.process(frame_rgb)\n",
    "            hand_results = hands.process(frame_rgb)\n",
    "            frame_rgb.flags.writeable = True\n",
    "            frame = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Drawing the landmarks\n",
    "            if pose_results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame,\n",
    "                    pose_results.pose_landmarks,\n",
    "                    mp_pose.POSE_CONNECTIONS,\n",
    "                    landmark_drawing_spec=pose_drawing_spec,\n",
    "                    connection_drawing_spec=pose_drawing_spec)\n",
    "\n",
    "            if hand_results.multi_hand_landmarks:\n",
    "                for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        frame,\n",
    "                        hand_landmarks,\n",
    "                        mp_hands.HAND_CONNECTIONS,\n",
    "                        landmark_drawing_spec=hand_drawing_spec,\n",
    "                        connection_drawing_spec=hand_drawing_spec)\n",
    "\n",
    "            row = ['', accuracy, sequence if record else -1]\n",
    "\n",
    "            if pose_results.pose_landmarks:\n",
    "                for lm in pose_results.pose_landmarks.landmark:\n",
    "                    visibility_binary = 1 if lm.visibility > 0.3 else 0\n",
    "                    row.extend([lm.x, lm.y, lm.z, visibility_binary])\n",
    "            else:\n",
    "                row.extend([0] * 33 * 4)\n",
    "\n",
    "            for hand in ('right_hand', 'left_hand'):\n",
    "                found = False\n",
    "                if hand_results.multi_hand_landmarks:\n",
    "                    for hand_landmarks, handedness in zip(hand_results.multi_hand_landmarks, hand_results.multi_handedness):\n",
    "                        if handedness.classification[0].label == ('Right' if hand == 'right_hand' else 'Left'):\n",
    "                            for lm in hand_landmarks.landmark:\n",
    "                                visibility_binary = 1 if lm.visibility > 0.2 else 0\n",
    "                                row.extend([lm.x, lm.y, lm.z, visibility_binary])\n",
    "                            found = True\n",
    "                            break\n",
    "                if not found:\n",
    "                    row.extend([0] * 21 * 4)\n",
    "\n",
    "            if record:\n",
    "                csv_writer.writerow(row)\n",
    "\n",
    "            out.write(frame)\n",
    "            cv2.imshow('MediaPipe Pose', frame)\n",
    "            key = cv2.waitKey(5) & 0xFF\n",
    "            if key == ord('r') or key == ord('w'):\n",
    "                new_state = chr(key)\n",
    "                if new_state != recording_state:\n",
    "                    sequence += 1  # Increment sequence only when state changes\n",
    "                    recording_state = new_state\n",
    "                record = True\n",
    "                accuracy = 1 if key == ord('r') else 0\n",
    "            elif key == ord('s'):\n",
    "                record = False\n",
    "                recording_state = None  # Reset recording state\n",
    "            elif key == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# write 'class' for first movement\n",
    "df = pd.read_csv('coordinates_1.csv')\n",
    "df.loc[df['accuracy'].notna(), 'class'] = 'movement_1'  \n",
    "df.to_csv('coordinates_1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1715161177.503264  138801 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2 Pro\n",
      "I0000 00:00:1715161177.507710  138801 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2 Pro\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Capture data for second 'movement'\n",
    "cap = cv2.VideoCapture('_.mp4')\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video capture\")\n",
    "else:\n",
    "    # Retrieving video properties\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30\n",
    "\n",
    "    # Setting up video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter('processed_output.avi', fourcc, fps, (width, height))\n",
    "\n",
    "    # MediaPipe pose and hand solutions initialization\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    pose_drawing_spec = mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4)\n",
    "    hand_drawing_spec = mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2)\n",
    "\n",
    "    record = False\n",
    "    accuracy = None\n",
    "    sequence = -1  \n",
    "    recording_state = None  \n",
    "\n",
    "    # Open the CSV file for appending data\n",
    "    with open('coordinates_2.csv', mode='a', newline='') as file:\n",
    "        csv_writer = csv.writer(file)\n",
    "\n",
    "        while cap.isOpened():\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                print(\"Error: Unable to read frame from video capture\")\n",
    "                break\n",
    "\n",
    "            # Convert the frame to RGB for processing\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_rgb.flags.writeable = False\n",
    "            pose_results = pose.process(frame_rgb)\n",
    "            hand_results = hands.process(frame_rgb)\n",
    "            frame_rgb.flags.writeable = True\n",
    "            frame = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Drawing the landmarks on the frame\n",
    "            if pose_results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame,\n",
    "                    pose_results.pose_landmarks,\n",
    "                    mp_pose.POSE_CONNECTIONS,\n",
    "                    landmark_drawing_spec=pose_drawing_spec,\n",
    "                    connection_drawing_spec=pose_drawing_spec)\n",
    "\n",
    "            if hand_results.multi_hand_landmarks:\n",
    "                for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        frame,\n",
    "                        hand_landmarks,\n",
    "                        mp_hands.HAND_CONNECTIONS,\n",
    "                        landmark_drawing_spec=hand_drawing_spec,\n",
    "                        connection_drawing_spec=hand_drawing_spec)\n",
    "\n",
    "            # Initialize the row with label 'movement_2'\n",
    "            row = ['movement_2', accuracy if accuracy is not None else '', sequence if record else -1]\n",
    "\n",
    "            # Append pose landmarks to the row\n",
    "            if pose_results.pose_landmarks:\n",
    "                for lm in pose_results.pose_landmarks.landmark:\n",
    "                    visibility_binary = 1 if lm.visibility > 0.3 else 0\n",
    "                    row.extend([lm.x, lm.y, lm.z, visibility_binary])\n",
    "            else:\n",
    "                row.extend([0] * 33 * 4)\n",
    "\n",
    "            # Append hand landmarks to the row\n",
    "            for hand in ('right_hand', 'left_hand'):\n",
    "                found = False\n",
    "                if hand_results.multi_hand_landmarks:\n",
    "                    for hand_landmarks, handedness in zip(hand_results.multi_hand_landmarks, hand_results.multi_handedness):\n",
    "                        if handedness.classification[0].label == ('Right' if hand == 'right_hand' else 'Left'):\n",
    "                            for lm in hand_landmarks.landmark:\n",
    "                                visibility_binary = 1 if lm.visibility > 0.2 else 0\n",
    "                                row.extend([lm.x, lm.y, lm.z, visibility_binary])\n",
    "                            found = True\n",
    "                            break\n",
    "                if not found:\n",
    "                    row.extend([0] * 21 * 4)\n",
    "\n",
    "            # Write the row to CSV if recording is active\n",
    "            if record:\n",
    "                csv_writer.writerow(row)\n",
    "\n",
    "            # Show the frame\n",
    "            out.write(frame)\n",
    "            cv2.imshow('MediaPipe Pose', frame)\n",
    "            key = cv2.waitKey(5) & 0xFF\n",
    "            if key == ord('r') or key == ord('w'):\n",
    "                new_state = chr(key)\n",
    "                if new_state != recording_state:\n",
    "                    sequence += 1  \n",
    "                    recording_state = new_state\n",
    "                record = True\n",
    "                accuracy = 1 if key == ord('r') else 0\n",
    "            elif key == ord('s'):\n",
    "                record = False\n",
    "                recording_state = None\n",
    "            elif key == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Join all the CSVs of the different movements\n",
    "df1 = pd.read_csv('coordinates_1.csv', header=None)\n",
    "df2 = pd.read_csv('coordinates_2.csv', header=None)\n",
    "\n",
    "# Concatenate along rows\n",
    "combined_df = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "\n",
    "# Save combined DataFrame to a new CSV\n",
    "combined_path = 'combined_coordinates.csv'\n",
    "combined_df.to_csv(combined_path, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class', 'accuracy', 'sequence', 'pose_x0', 'pose_y0', 'pose_z0', 'pose_v0', 'pose_x1', 'pose_y1', 'pose_z1', 'pose_v1', 'pose_x2', 'pose_y2', 'pose_z2', 'pose_v2', 'pose_x3', 'pose_y3', 'pose_z3', 'pose_v3', 'pose_x4', 'pose_y4', 'pose_z4', 'pose_v4', 'pose_x5', 'pose_y5', 'pose_z5', 'pose_v5', 'pose_x6', 'pose_y6', 'pose_z6', 'pose_v6', 'pose_x7', 'pose_y7', 'pose_z7', 'pose_v7', 'pose_x8', 'pose_y8', 'pose_z8', 'pose_v8', 'pose_x9', 'pose_y9', 'pose_z9', 'pose_v9', 'pose_x10', 'pose_y10', 'pose_z10', 'pose_v10', 'pose_x11', 'pose_y11', 'pose_z11', 'pose_v11', 'pose_x12', 'pose_y12', 'pose_z12', 'pose_v12', 'pose_x13', 'pose_y13', 'pose_z13', 'pose_v13', 'pose_x14', 'pose_y14', 'pose_z14', 'pose_v14', 'pose_x15', 'pose_y15', 'pose_z15', 'pose_v15', 'pose_x16', 'pose_y16', 'pose_z16', 'pose_v16', 'pose_x17', 'pose_y17', 'pose_z17', 'pose_v17', 'pose_x18', 'pose_y18', 'pose_z18', 'pose_v18', 'pose_x19', 'pose_y19', 'pose_z19', 'pose_v19', 'pose_x20', 'pose_y20', 'pose_z20', 'pose_v20', 'pose_x21', 'pose_y21', 'pose_z21', 'pose_v21', 'pose_x22', 'pose_y22', 'pose_z22', 'pose_v22', 'pose_x23', 'pose_y23', 'pose_z23', 'pose_v23', 'pose_x24', 'pose_y24', 'pose_z24', 'pose_v24', 'pose_x25', 'pose_y25', 'pose_z25', 'pose_v25', 'pose_x26', 'pose_y26', 'pose_z26', 'pose_v26', 'pose_x27', 'pose_y27', 'pose_z27', 'pose_v27', 'pose_x28', 'pose_y28', 'pose_z28', 'pose_v28', 'pose_x29', 'pose_y29', 'pose_z29', 'pose_v29', 'pose_x30', 'pose_y30', 'pose_z30', 'pose_v30', 'pose_x31', 'pose_y31', 'pose_z31', 'pose_v31', 'pose_x32', 'pose_y32', 'pose_z32', 'pose_v32', 'right_hand_x0', 'right_hand_y0', 'right_hand_z0', 'right_hand_v0', 'right_hand_x1', 'right_hand_y1', 'right_hand_z1', 'right_hand_v1', 'right_hand_x2', 'right_hand_y2', 'right_hand_z2', 'right_hand_v2', 'right_hand_x3', 'right_hand_y3', 'right_hand_z3', 'right_hand_v3', 'right_hand_x4', 'right_hand_y4', 'right_hand_z4', 'right_hand_v4', 'right_hand_x5', 'right_hand_y5', 'right_hand_z5', 'right_hand_v5', 'right_hand_x6', 'right_hand_y6', 'right_hand_z6', 'right_hand_v6', 'right_hand_x7', 'right_hand_y7', 'right_hand_z7', 'right_hand_v7', 'right_hand_x8', 'right_hand_y8', 'right_hand_z8', 'right_hand_v8', 'right_hand_x9', 'right_hand_y9', 'right_hand_z9', 'right_hand_v9', 'right_hand_x10', 'right_hand_y10', 'right_hand_z10', 'right_hand_v10', 'right_hand_x11', 'right_hand_y11', 'right_hand_z11', 'right_hand_v11', 'right_hand_x12', 'right_hand_y12', 'right_hand_z12', 'right_hand_v12', 'right_hand_x13', 'right_hand_y13', 'right_hand_z13', 'right_hand_v13', 'right_hand_x14', 'right_hand_y14', 'right_hand_z14', 'right_hand_v14', 'right_hand_x15', 'right_hand_y15', 'right_hand_z15', 'right_hand_v15', 'right_hand_x16', 'right_hand_y16', 'right_hand_z16', 'right_hand_v16', 'right_hand_x17', 'right_hand_y17', 'right_hand_z17', 'right_hand_v17', 'right_hand_x18', 'right_hand_y18', 'right_hand_z18', 'right_hand_v18', 'right_hand_x19', 'right_hand_y19', 'right_hand_z19', 'right_hand_v19', 'right_hand_x20', 'right_hand_y20', 'right_hand_z20', 'right_hand_v20', 'left_hand_x0', 'left_hand_y0', 'left_hand_z0', 'left_hand_v0', 'left_hand_x1', 'left_hand_y1', 'left_hand_z1', 'left_hand_v1', 'left_hand_x2', 'left_hand_y2', 'left_hand_z2', 'left_hand_v2', 'left_hand_x3', 'left_hand_y3', 'left_hand_z3', 'left_hand_v3', 'left_hand_x4', 'left_hand_y4', 'left_hand_z4', 'left_hand_v4', 'left_hand_x5', 'left_hand_y5', 'left_hand_z5', 'left_hand_v5', 'left_hand_x6', 'left_hand_y6', 'left_hand_z6', 'left_hand_v6', 'left_hand_x7', 'left_hand_y7', 'left_hand_z7', 'left_hand_v7', 'left_hand_x8', 'left_hand_y8', 'left_hand_z8', 'left_hand_v8', 'left_hand_x9', 'left_hand_y9', 'left_hand_z9', 'left_hand_v9', 'left_hand_x10', 'left_hand_y10', 'left_hand_z10', 'left_hand_v10', 'left_hand_x11', 'left_hand_y11', 'left_hand_z11', 'left_hand_v11', 'left_hand_x12', 'left_hand_y12', 'left_hand_z12', 'left_hand_v12', 'left_hand_x13', 'left_hand_y13', 'left_hand_z13', 'left_hand_v13', 'left_hand_x14', 'left_hand_y14', 'left_hand_z14', 'left_hand_v14', 'left_hand_x15', 'left_hand_y15', 'left_hand_z15', 'left_hand_v15', 'left_hand_x16', 'left_hand_y16', 'left_hand_z16', 'left_hand_v16', 'left_hand_x17', 'left_hand_y17', 'left_hand_z17', 'left_hand_v17', 'left_hand_x18', 'left_hand_y18', 'left_hand_z18', 'left_hand_v18', 'left_hand_x19', 'left_hand_y19', 'left_hand_z19', 'left_hand_v19', 'left_hand_x20', 'left_hand_y20', 'left_hand_z20', 'left_hand_v20']\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Delete not important data\n",
    "data = pd.read_csv('combined_coordinates.csv')\n",
    "\n",
    "# Display column names to understand what columns are actually in the dataset\n",
    "print(data.columns.tolist())\n",
    "\n",
    "# Define columns to remove by ensuring they exist in the DataFrame's columns\n",
    "columns_to_remove_1 = [f\"pose_{c}{i}\" for c in ['x', 'y', 'z', 'v'] for i in range(0, 11)]\n",
    "columns_to_remove_2 = [f\"pose_{c}{i}\" for c in ['x', 'y', 'z', 'v'] for i in range(23, 33)]\n",
    "columns_to_remove = [col for col in (columns_to_remove_1 + columns_to_remove_2) if col in data.columns]\n",
    "\n",
    "# Drop these columns from the DataFrame\n",
    "data_filtered = data.drop(columns=columns_to_remove)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "data_filtered.to_csv('filtered_coordinates.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>sequence</th>\n",
       "      <th>pose_x11</th>\n",
       "      <th>pose_y11</th>\n",
       "      <th>pose_z11</th>\n",
       "      <th>pose_v11</th>\n",
       "      <th>pose_x12</th>\n",
       "      <th>pose_y12</th>\n",
       "      <th>pose_z12</th>\n",
       "      <th>...</th>\n",
       "      <th>left_hand_z18</th>\n",
       "      <th>left_hand_v18</th>\n",
       "      <th>left_hand_x19</th>\n",
       "      <th>left_hand_y19</th>\n",
       "      <th>left_hand_z19</th>\n",
       "      <th>left_hand_v19</th>\n",
       "      <th>left_hand_x20</th>\n",
       "      <th>left_hand_y20</th>\n",
       "      <th>left_hand_z20</th>\n",
       "      <th>left_hand_v20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movement_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.412</td>\n",
       "      <td>-0.578</td>\n",
       "      <td>1</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.546</td>\n",
       "      <td>-0.492</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movement_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.406</td>\n",
       "      <td>-0.603</td>\n",
       "      <td>1</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.526</td>\n",
       "      <td>-0.521</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movement_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.416</td>\n",
       "      <td>-0.578</td>\n",
       "      <td>1</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.570</td>\n",
       "      <td>-0.540</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>movement_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.395</td>\n",
       "      <td>-0.452</td>\n",
       "      <td>1</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.540</td>\n",
       "      <td>-0.390</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>movement_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.393</td>\n",
       "      <td>-0.477</td>\n",
       "      <td>1</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.544</td>\n",
       "      <td>-0.434</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 219 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        class  accuracy  sequence  pose_x11  pose_y11  pose_z11  pose_v11  \\\n",
       "0  movement_1         0         0     0.378     0.412    -0.578         1   \n",
       "1  movement_1         0         0     0.378     0.406    -0.603         1   \n",
       "2  movement_1         0         0     0.391     0.416    -0.578         1   \n",
       "3  movement_1         0         0     0.381     0.395    -0.452         1   \n",
       "4  movement_1         0         0     0.379     0.393    -0.477         1   \n",
       "\n",
       "   pose_x12  pose_y12  pose_z12  ...  left_hand_z18  left_hand_v18  \\\n",
       "0     0.151     0.546    -0.492  ...              0              0   \n",
       "1     0.159     0.526    -0.521  ...              0              0   \n",
       "2     0.158     0.570    -0.540  ...              0              0   \n",
       "3     0.158     0.540    -0.390  ...              0              0   \n",
       "4     0.160     0.544    -0.434  ...              0              0   \n",
       "\n",
       "   left_hand_x19  left_hand_y19  left_hand_z19  left_hand_v19  left_hand_x20  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   left_hand_y20  left_hand_z20  left_hand_v20  \n",
       "0              0              0              0  \n",
       "1              0              0              0  \n",
       "2              0              0              0  \n",
       "3              0              0              0  \n",
       "4              0              0              0  \n",
       "\n",
       "[5 rows x 219 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 10: Reduce decimal points\n",
    "data = pd.read_csv('filtered_coordinates.csv')\n",
    "data = data.round(3)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mynewv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
